"""
Tools for Synthetic Data Generator - With SDK Context Management
Herramientas que usan el contexto del SDK para mantener estado entre llamadas
"""

import os
import logging
import pandas as pd
import uuid
import tempfile
from typing import Dict, Any, Optional
from dataclasses import dataclass, field
from agents import function_tool, RunContextWrapper

# Setup logging
logger = logging.getLogger(__name__)

# ==========================================
# CONTEXTO PARA EL SDK
# ==========================================

@dataclass
class SyntheticDataContext:
    """
    Contexto que se pasa al SDK y mantiene estado entre herramientas
    """
    user_id: str
    session_id: str
    temp_dir: str = field(default_factory=lambda: tempfile.mkdtemp(prefix="synthetic_data_"))
    
    # Estado de archivos
    analyzed_file_path: Optional[str] = None
    analyzed_file_info: Optional[Dict[str, Any]] = None
    generated_file_path: Optional[str] = None
    generated_file_id: Optional[str] = None
    generated_rows: Optional[int] = None
    
    # Metadatos de proceso
    last_model_used: Optional[str] = None
    processing_history: list = field(default_factory=list)
    current_agent: Optional[str] = None
    
    def add_to_history(self, action: str, details: Dict[str, Any]):
        """Agregar acci√≥n al historial"""
        self.processing_history.append({
            "timestamp": pd.Timestamp.now().isoformat(),
            "action": action,
            "details": details
        })

# ==========================================
# HERRAMIENTAS CON CONTEXTO DEL SDK
# ==========================================

@function_tool
def analyze_csv_file(wrapper: RunContextWrapper[SyntheticDataContext], file_path: str) -> Dict[str, Any]:
    """
    Analiza un archivo CSV y guarda la informaci√≥n en el contexto para uso posterior.
    
    Args:
        file_path: Ruta completa al archivo CSV a analizar
        
    Returns:
        Diccionario con estad√≠sticas del archivo CSV
    """
    try:
        # Obtener contexto del SDK
        context = wrapper.context
        
        # Cargar CSV
        df = pd.read_csv(file_path)
        
        # An√°lisis completo del archivo
        analysis = {
            "success": True,
            "file_path": file_path,
            "filename": os.path.basename(file_path),
            "rows": len(df),
            "columns": list(df.columns),
            "column_count": len(df.columns),
            "data_types": {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()},
            "missing_values": df.isnull().sum().to_dict(),
            "missing_percentage": (df.isnull().sum() / len(df) * 100).round(2).to_dict(),
            "memory_usage_mb": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2),
            "numeric_columns": df.select_dtypes(include=['number']).columns.tolist(),
            "categorical_columns": df.select_dtypes(include=['object']).columns.tolist(),
            "sample_data": df.head(3).to_dict('records'),
            "basic_stats": df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else {}
        }
        
        # üéØ GUARDAR EN CONTEXTO para uso posterior
        context.analyzed_file_path = file_path
        context.analyzed_file_info = analysis
        context.add_to_history("csv_analyzed", {
            "file_path": file_path,
            "rows": len(df),
            "columns": len(df.columns)
        })
        
        logger.info(f"‚úÖ CSV analizado y guardado en contexto: {os.path.basename(file_path)} - {len(df)} filas, {len(df.columns)} columnas")
        return analysis
        
    except FileNotFoundError:
        error_msg = f"‚ùå Archivo no encontrado: {file_path}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}
    except pd.errors.EmptyDataError:
        error_msg = "‚ùå El archivo CSV est√° vac√≠o"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}
    except pd.errors.ParserError as e:
        error_msg = f"‚ùå Error parsing CSV: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}
    except Exception as e:
        error_msg = f"‚ùå Error inesperado analizando CSV: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}


@function_tool
def generate_synthetic_data_with_sdv(
    wrapper: RunContextWrapper[SyntheticDataContext],
    num_rows: int,
    model_type: str = "GaussianCopula"
) -> Dict[str, Any]:
    """
    Genera datos sint√©ticos usando SDV. Usa autom√°ticamente el archivo previamente analizado.
    
    Args:
        num_rows: N√∫mero de filas sint√©ticas a generar
        model_type: Tipo de modelo SDV (GaussianCopula, CTGAN, CopulaGAN, TVAE)
        
    Returns:
        Diccionario con informaci√≥n del archivo generado
    """
    try:
        # Obtener contexto del SDK
        context = wrapper.context
        
        # üéØ USAR ARCHIVO DEL CONTEXTO
        if not context.analyzed_file_path:
            return {
                "success": False,
                "error": "‚ùå Primero debes analizar un archivo CSV usando analyze_csv_file()"
            }
        
        source_file_path = context.analyzed_file_path
        
        # Cargar datos fuente
        source_df = pd.read_csv(source_file_path)
        
        # Validaciones b√°sicas
        if len(source_df) < 2:
            return {
                "success": False,
                "error": "‚ùå Se necesitan al menos 2 filas en los datos fuente para entrenar el modelo"
            }
        
        if num_rows <= 0:
            return {
                "success": False,
                "error": "‚ùå El n√∫mero de filas debe ser mayor a 0"
            }
        
        if num_rows > 100000:
            return {
                "success": False,
                "error": "‚ùå M√°ximo 100,000 filas por generaci√≥n para evitar problemas de memoria"
            }
        
        # Import SDV basado en el modelo seleccionado (SDV 1.0+)
        try:
            from sdv.metadata import SingleTableMetadata
            
            if model_type == "GaussianCopula":
                from sdv.single_table import GaussianCopulaSynthesizer as Synthesizer
            elif model_type == "CTGAN":
                from sdv.single_table import CTGANSynthesizer as Synthesizer
            elif model_type == "CopulaGAN":
                from sdv.single_table import CopulaGANSynthesizer as Synthesizer
            elif model_type == "TVAE":
                from sdv.single_table import TVAESynthesizer as Synthesizer
            else:
                return {
                    "success": False,
                    "error": f"‚ùå Modelo no soportado: {model_type}. Modelos disponibles: GaussianCopula, CTGAN, CopulaGAN, TVAE"
                }
        except ImportError as e:
            return {
                "success": False,
                "error": "‚ùå SDV no est√° instalado correctamente. Instala con: pip install sdv"
            }
        
        logger.info(f"üöÄ Iniciando entrenamiento {model_type} con {len(source_df)} filas fuente")
        
        # Crear metadatos autom√°ticamente (SDV 1.0+ requirement)
        try:
            metadata = SingleTableMetadata()
            metadata.detect_from_dataframe(source_df)
            logger.info(f"üìä Metadatos detectados: {len(metadata.columns)} columnas")
        except Exception as e:
            return {
                "success": False,
                "error": f"‚ùå Error creando metadatos: {str(e)}"
            }
        
        # Entrenar modelo SDV con metadatos
        try:
            synthesizer = Synthesizer(metadata)
            synthesizer.fit(source_df)
        except Exception as e:
            return {
                "success": False,
                "error": f"‚ùå Error entrenando modelo {model_type}: {str(e)}"
            }
        
        logger.info(f"üéØ Generando {num_rows} filas sint√©ticas...")
        
        # Generar datos sint√©ticos
        synthetic_data = synthesizer.sample(num_rows)
        
        # Crear archivo con nombre descriptivo en directorio de trabajo
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        source_filename = os.path.splitext(os.path.basename(source_file_path))[0]
        output_filename = f"{source_filename}_synthetic_data_{model_type.lower()}_{num_rows}rows_{timestamp}.csv"
        
        # Guardar en directorio de trabajo actual
        current_dir = os.getcwd()
        output_path = os.path.join(current_dir, output_filename)
        
        # Guardar archivo CSV
        synthetic_data.to_csv(output_path, index=False)
        
        # Calcular m√©tricas b√°sicas
        file_size_mb = round(os.path.getsize(output_path) / 1024 / 1024, 2)
        
        # üéØ ACTUALIZAR CONTEXTO
        context.generated_file_path = output_path
        context.generated_file_id = timestamp  # Usar timestamp como ID
        context.generated_rows = num_rows
        context.last_model_used = model_type
        context.add_to_history("synthetic_data_generated", {
            "model_type": model_type,
            "num_rows": num_rows,
            "output_filename": output_filename,
            "file_size_mb": file_size_mb,
            "saved_to": "current_directory"
        })
        
        result = {
            "success": True,
            "file_id": timestamp,
            "output_filename": output_filename,
            "output_path": output_path,
            "saved_in_current_directory": True,
            "full_path_for_access": output_path,
            "rows_generated": num_rows,
            "columns": list(synthetic_data.columns),
            "model_used": model_type,
            "source_file": os.path.basename(source_file_path),
            "source_rows": len(source_df),
            "file_size_mb": file_size_mb,
            "sample_synthetic_data": synthetic_data.head(3).to_dict('records'),
            "generation_summary": f"‚úÖ Generadas {num_rows:,} filas sint√©ticas usando {model_type} desde {len(source_df):,} filas originales",
            "access_instructions": f"El archivo se guard√≥ en: {output_path}"
        }
        
        logger.info(f"‚úÖ Datos sint√©ticos generados y guardados en contexto: {output_filename} ({file_size_mb}MB)")
        return result
        
    except Exception as e:
        error_msg = f"‚ùå Error generando datos con SDV: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}


@function_tool
def list_sdv_models() -> Dict[str, Any]:
    """
    Lista los modelos SDV disponibles con sus descripciones y recomendaciones.
    
    Returns:
        Diccionario con informaci√≥n de todos los modelos SDV
    """
    models_info = {
        "success": True,
        "available_models": {
            "GaussianCopula": {
                "name": "GaussianCopula",
                "description": "Modelo r√°pido y eficiente basado en c√≥pulas gaussianas",
                "pros": ["Muy r√°pido", "Bajo uso de memoria", "Bueno para datos num√©ricos"],
                "cons": ["Limitado con datos categ√≥ricos complejos", "Asume distribuciones gaussianas"],
                "best_for": "Datasets con principalmente datos num√©ricos, cuando necesitas velocidad",
                "training_time": "Segundos",
                "quality": "Buena",
                "recommended_for": ["Prototipos r√°pidos", "Datos principalmente num√©ricos", "Datasets peque√±os-medianos"]
            },
            "CTGAN": {
                "name": "CTGAN",
                "description": "Red neuronal generativa adversarial para datos tabulares",
                "pros": ["Excelente calidad", "Maneja bien datos categ√≥ricos", "Muy realista"],
                "cons": ["Lento", "Consume mucha memoria", "Necesita m√°s datos de entrenamiento"],
                "best_for": "M√°xima calidad con datos complejos y muchas categor√≠as",
                "training_time": "Minutos a horas",
                "quality": "Excelente",
                "recommended_for": ["Datos complejos", "Muchas columnas categ√≥ricas", "Cuando la calidad es prioritaria"]
            },
            "CopulaGAN": {
                "name": "CopulaGAN",
                "description": "H√≠brido que combina c√≥pulas con redes neuronales",
                "pros": ["Balance velocidad/calidad", "Vers√°til", "Buen rendimiento general"],
                "cons": ["No es el mejor en ning√∫n aspecto espec√≠fico"],
                "best_for": "Caso general cuando quieres balance entre velocidad y calidad",
                "training_time": "Minutos",
                "quality": "Muy buena",
                "recommended_for": ["Uso general", "Datasets mixtos", "Cuando no sabes qu√© modelo elegir"]
            },
            "TVAE": {
                "name": "TVAE",
                "description": "Autoencoder variacional tabular",
                "pros": ["Excelente con valores faltantes", "Buena calidad", "Robusto"],
                "cons": ["M√°s lento que GaussianCopula", "Configuraci√≥n m√°s compleja"],
                "best_for": "Datos con muchos valores faltantes o distribuciones complejas",
                "training_time": "Minutos",
                "quality": "Muy buena",
                "recommended_for": ["Datos con valores faltantes", "Distribuciones no gaussianas", "Datos de salud/financieros"]
            }
        },
        "selection_guide": {
            "fast_prototype": "GaussianCopula",
            "maximum_quality": "CTGAN", 
            "balanced_choice": "CopulaGAN",
            "missing_values": "TVAE",
            "large_dataset": "GaussianCopula",
            "small_dataset": "CTGAN o TVAE",
            "mostly_numeric": "GaussianCopula",
            "mostly_categorical": "CTGAN",
            "mixed_data": "CopulaGAN"
        }
    }
    
    return models_info


@function_tool
def create_download_link(wrapper: RunContextWrapper[SyntheticDataContext]) -> Dict[str, Any]:
    """
    Crea un enlace de descarga para el archivo generado previamente.
    
    Returns:
        Informaci√≥n del enlace de descarga
    """
    try:
        # Obtener contexto del SDK
        context = wrapper.context
        
        # Verificar que hay archivo generado
        if not context.generated_file_id or not context.generated_file_path:
            return {
                "success": False,
                "error": "‚ùå No hay archivos generados disponibles para descargar. Primero genera datos sint√©ticos."
            }
        
        # Verificar que el archivo existe
        if not os.path.exists(context.generated_file_path):
            return {
                "success": False,
                "error": "‚ùå El archivo generado no se encuentra en el sistema"
            }
        
        # Crear informaci√≥n de descarga
        download_info = {
            "success": True,
            "file_id": context.generated_file_id,
            "download_url": f"/download/{context.generated_file_id}?session_id={context.session_id}",
            "filename": os.path.basename(context.generated_file_path),
            "rows": context.generated_rows,
            "model_used": context.last_model_used,
            "file_size_mb": round(os.path.getsize(context.generated_file_path) / 1024 / 1024, 2),
            "created_at": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            "full_path": context.generated_file_path
        }
        
        context.add_to_history("download_link_created", {
            "file_id": context.generated_file_id,
            "filename": os.path.basename(context.generated_file_path)
        })
        
        logger.info(f"üì• Enlace de descarga creado para archivo: {context.generated_file_id}")
        return download_info
        
    except Exception as e:
        error_msg = f"‚ùå Error creando enlace de descarga: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}


@function_tool
def get_session_status(wrapper: RunContextWrapper[SyntheticDataContext]) -> Dict[str, Any]:
    """
    Obtiene el estado completo de la sesi√≥n actual.
    
    Returns:
        Estado completo de la sesi√≥n y archivos
    """
    try:
        # Obtener contexto del SDK
        context = wrapper.context
        
        session_status = {
            "success": True,
            "session_info": {
                "session_id": context.session_id,
                "user_id": context.user_id,
                "temp_directory": context.temp_dir
            },
            "analyzed_file": {
                "has_file": bool(context.analyzed_file_path),
                "file_path": context.analyzed_file_path,
                "file_info": context.analyzed_file_info
            },
            "generated_file": {
                "has_file": bool(context.generated_file_id),
                "file_id": context.generated_file_id,
                "file_path": context.generated_file_path,
                "rows_generated": context.generated_rows,
                "model_used": context.last_model_used
            },
            "processing_history": context.processing_history[-5:] if context.processing_history else [],  # √öltimas 5 acciones
            "total_actions": len(context.processing_history)
        }
        
        return session_status
        
    except Exception as e:
        error_msg = f"‚ùå Error obteniendo estado de sesi√≥n: {str(e)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg}


# ==========================================
# UTILIDADES PARA AGENTES
# ==========================================

def get_tools_for_agent(agent_type: str) -> list:
    """
    Retorna herramientas espec√≠ficas para un tipo de agente.
    
    Args:
        agent_type: Tipo de agente
        
    Returns:
        Lista de function_tools para el agente
    """
    if agent_type == "sample_data":
        return [
            analyze_csv_file,
            list_sdv_models,
            generate_synthetic_data_with_sdv,
            create_download_link,
            get_session_status
        ]
    elif agent_type == "pure_synthetic":
        # Import local para evitar circular import
        from pure_tools_simple import generate_synthetic_data_simple
        return [
            generate_synthetic_data_simple,
            get_session_status
        ]
    elif agent_type == "orchestrator":
        return [
            get_session_status
        ]
    elif agent_type == "pure_historical":
        return [
            # TODO: Agregar herramientas para carga de datos hist√≥ricos
            get_session_status
        ]
    else:
        # Retornar todas las herramientas disponibles
        return [
            analyze_csv_file,
            list_sdv_models,
            generate_synthetic_data_with_sdv,
            create_download_link,
            get_session_status
        ]